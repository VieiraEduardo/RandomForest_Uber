{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VieiraEduardo/RandomForest_Uber/blob/main/RandomForestUber.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii07CyguSaie"
      },
      "source": [
        "## Pipeline de Ciência de Dados ##\n",
        "\n",
        "É importante definir todas as fases de criação de criação de um projeto que envolve Ciências de Dados, para detectar o problema de negócio e o objetivo desejado de forma eficiente.\n",
        "\n",
        "1.Problema de Negócio\n",
        "\n",
        "Prever o cancelamento das viagens que é a classificação de status da reserva.\n",
        "\n",
        "2.Coleta e armasentamento de dados\n",
        "\n",
        "Dados adquiridos do Kaggle\n",
        "\n",
        "3.Pré Processamento e limpeza dos dados\n",
        "\n",
        "4.Analise Exploratória dos Dados\n",
        "\n",
        "5.Modelagem\n",
        "\n",
        "6.Avaliação de Modelo\n",
        "\n",
        "7.Interpretação e comunicação dos resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WY3tqBtXQ-Z8"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas a utilizar\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "373545c5"
      },
      "outputs": [],
      "source": [
        "!pip install ydata-profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ9fMaMRURz9"
      },
      "outputs": [],
      "source": [
        "# Carregar e ler dataset\n",
        "df = pd.read_csv('/content/ncr_ride_bookings.csv', index_col='Customer ID')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5qFiTl8RKQS"
      },
      "outputs": [],
      "source": [
        "# Verificar informações do dataset\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "181wtj1A1W67"
      },
      "source": [
        "## 3. Pré Processamento e Limpeza dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCJHvKRChXDP"
      },
      "outputs": [],
      "source": [
        "# 2. Assegurar que as colunas 'Date' e 'Time' são do tipo string para evitar erros.\n",
        "df['Date'] = df['Date'].astype(str)\n",
        "df['Time'] = df['Time'].astype(str)\n",
        "\n",
        "# 3. Combinar as colunas 'Date' e 'Time' em uma única coluna 'DateTime'.\n",
        "df['DateTime'] = df['Date'] + ' ' + df['Time']\n",
        "\n",
        "# 4. Converter a nova coluna 'DateTime' para o tipo datetime.\n",
        "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
        "\n",
        "# 5. (Opcional) Criar novas colunas para análise, como o dia da semana.\n",
        "df['DayOfWeek'] = df['DateTime'].dt.day_name()\n",
        "df['Hour'] = df['DateTime'].dt.hour\n",
        "\n",
        "#Excluir coluna Date e coluna Time\n",
        "df.drop(['Date', 'Time'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5E1eT0yh02i"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6ULyAX2rhro"
      },
      "outputs": [],
      "source": [
        "# Alinhar cabeçalho do df\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcywZBeFAKW0"
      },
      "outputs": [],
      "source": [
        "# Remover primeira linha não mais necessária\n",
        "df.drop(df.index[0], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ew1uIYXs0ZjN"
      },
      "outputs": [],
      "source": [
        "# Verificar linhas do dataset de forma aleatoria\n",
        "df.sample(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oTx2DK_YGLW"
      },
      "outputs": [],
      "source": [
        "# verificar as colunas que contem dados nulos\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2O4yYZ1pyO1"
      },
      "source": [
        "##Observação\n",
        "\n",
        "É perceptivel que mais da metade das colunas tem valores nulos/sem informação, isso para um modelo preditivo pode enviesar o modelo se não bem tratado. É necessário entender se aqueles valores realmente tem ou não informação úteis, ou se não foram devidadamente preenchidos na hora da aquisição do Banco de Dados.\n",
        "Para melhor visualização e compreensão, colocar os valores null em porcetagem que dá um noção melhor se dá para trabalhar com determinada coluna.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-y_kmn_nLoV"
      },
      "outputs": [],
      "source": [
        "# Verificar quantos por % de dados nulos tem em cada coluna do Dataframe\n",
        "(df.isnull().sum()/df.shape[0])*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kL4DdQo6Ql3"
      },
      "source": [
        "##Observação\n",
        "\n",
        "Colunas com mais de 50% dos dados ausentes, após interpretação com o modelo de negócio, podem ser consideradas a se serem excluidas. Colunas com baixa porcentagem, seja até 10% ou 20% podemos realizar algumas tecnicas de imputação para tentar preencher esses valores ausentes.\n",
        "\n",
        "As colunas Driver Ratings e Customer Rating haviam 38% de dados ausentes, onde optei por fazer uma imputação pela mediana que é uma estratégia robusta aos valores da coluna e não distorce a distribuição dos dados, preservando e retendo o máximo de informação.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gFGVsKyAgvy3"
      },
      "outputs": [],
      "source": [
        "# substituir dados nan da coluna Driver Rating pela Mediana\n",
        "df['driver_ratings'].fillna(df['driver_ratings'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wwd1cqo7_i3"
      },
      "outputs": [],
      "source": [
        "# substituir dados nan da coluna Customer Rating pela Mediana\n",
        "df['customer_rating'].fillna(df['customer_rating'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KliDN7OM_DKK"
      },
      "source": [
        "## Oberservação\n",
        "\n",
        "Existem 4 colunas com mais de 80% com dados nulos. Cancelled Rides by Customer e reason for cancelling by customer\t(93%) e Reason for cancelled rides by driver  e Driver Cancellation Reason (82%).\n",
        "\n",
        "Ideal fazer uma imputação de dados onde optei pela seguinte estratégia:\n",
        "\n",
        "##Para Cancelled Rides by Customer e Cancelled Rides by Driver:\n",
        "\n",
        "Substituir os valores nulos por 0.\n",
        "\n",
        "Onde já existe o valor 1, eu os mantenho-o.\n",
        "\n",
        "O resulto obtido será uma variável binária (0 ou 1) que indica se o cancelamento partiu do motorista ou do cliente. Isso é perfeito para um modelo de classificação.\n",
        "\n",
        "##Para Reason for cancelling by Customer e Driver Cancellation Reason:\n",
        "\n",
        "Substituir os valores nulos por uma categoria como \"Não se Aplica\" ou \"Corrida Concluída\".\n",
        "\n",
        "Aos motivos de cancelamento existentes, como \"Vehicle Breakdown\". eu os mantenho-o.\n",
        "\n",
        "O resultado obtido será uma variável categórica que informa o motivo do cancelamento, o que pode ser um recurso valioso para o modelo entender o comportamento de clientes e motoristas.\n",
        "\n",
        "Ao fazer isso, eu não apenas preservo os dados, mas também crio variáveis poderosas com informação robusta que serão a base do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiaM7sQR9Zlp"
      },
      "outputs": [],
      "source": [
        "# Substituir os valores nulos da coluna Cancelled Rides by Costumer e Cancelled Rides bu Driver\n",
        "df['cancelled_rides_by_customer'].fillna(0, inplace=True)\n",
        "df['cancelled_rides_by_driver'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0jgNyUMDl3C"
      },
      "outputs": [],
      "source": [
        "# Substituir os valores nulos da coluna Cancelling by Customer e Driver Cancellation Reason por uma categoria Não se Aplica ou Corrida concluida\n",
        "df['reason_for_cancelling_by_customer'].fillna(' Não Se Aplica', inplace=True)\n",
        "df['driver_cancellation_reason'].fillna('Não Se Aplica', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEvC7WA0fOW7"
      },
      "outputs": [],
      "source": [
        "# Substituir dados das colunas avg_vtat, avg_ctat, booking value, Ride Distance pela mediana\n",
        "df['avg_vtat'].fillna(df['avg_vtat'].median(), inplace=True)\n",
        "df['avg_ctat'].fillna(df['avg_ctat'].median(), inplace=True)\n",
        "df['booking_value'].fillna(df['booking_value'].median(), inplace=True)\n",
        "df['ride_distance'].fillna(df['ride_distance'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF34Ra7ssFkr"
      },
      "outputs": [],
      "source": [
        "# Substituir os valores NAN da coluna imcomplete rides por 0\n",
        "df['incomplete_rides'].fillna(0, inplace=True)\n",
        "\n",
        "#Substituir os valores NAN da coluna Imcomplete rides reason por não se aplica\n",
        "df['incomplete_rides_reason'].fillna('Não Se Aplica', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cK3viiKN_Nwn"
      },
      "outputs": [],
      "source": [
        "# Substituir valores NAN da coluna Payment Method por Desconhecido\n",
        "df['payment_method'].fillna('Desconhecido', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrjR9s6C6DwQ"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiZ90umjwJrn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RvrkBafI055"
      },
      "outputs": [],
      "source": [
        "# Traduzir o nome de todas as colunas\n",
        "df.columns = df.columns.str.replace('booking_id', 'id_reserva')\n",
        "df.columns = df.columns.str.replace('booking_status', 'status_reserva')\n",
        "df.columns = df.columns.str.replace('vehicle_type', 'tipo_veiculo')\n",
        "df.columns = df.columns.str.replace('pickup_location', 'local_embarque')\n",
        "df.columns = df.columns.str.replace('drop_location', 'local_desembarque')\n",
        "df.columns = df.columns.str.replace('avg_vtat', 'tempo_medio_viagem')\n",
        "df.columns = df.columns.str.replace('avg_ctat', 'tempo_medio_cancelamento')\n",
        "df.columns = df.columns.str.replace('cancelled_rides_by_customer', 'cancelamentos_cliente')\n",
        "df.columns = df.columns.str.replace('reason_for_cancelling_by_customer', 'motivo_cancelamento_cliente')\n",
        "df.columns = df.columns.str.replace('cancelled_rides_by_driver', 'cancelamentos_motorista')\n",
        "df.columns = df.columns.str.replace('driver_cancellation_reason', 'motivo_cancelamento_motorista')\n",
        "df.columns = df.columns.str.replace('incomplete_rides', 'viagens_incompletas')\n",
        "df.columns = df.columns.str.replace('incomplete_rides_reason', 'motivo_viagens_incompletas')\n",
        "df.columns = df.columns.str.replace('booking_value', 'valor_reserva')\n",
        "df.columns = df.columns.str.replace('ride_distance', 'distancia_viagem')\n",
        "df.columns = df.columns.str.replace('driver_ratings', 'avaliacao_motorista')\n",
        "df.columns = df.columns.str.replace('customer_rating', 'avaliacao_cliente')\n",
        "df.columns = df.columns.str.replace('payment_method', 'metodo_pagamento')\n",
        "df.columns = df.columns.str.replace('datetime', 'data_hora')\n",
        "df.columns = df.columns.str.replace('dayofweek', 'dia_semana')\n",
        "df.columns = df.columns.str.replace('hour', 'hora')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Zloel0uIhfs"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsVrHiRP5JQE"
      },
      "outputs": [],
      "source": [
        "# 1. Calcular a distribuição e o percentual da variável-alvo\n",
        "status_counts = df['status_reserva'].value_counts()\n",
        "status_percentages = df['status_reserva'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"--- Distribuição Numérica do Booking Status ---\")\n",
        "print(pd.DataFrame({'Contagem': status_counts, 'Percentual': status_percentages.round(2).astype(str) + '%'}))\n",
        "\n",
        "# 3. Visualizar a distribuição (Gráfico de Barras)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=status_counts.index, y=status_counts.values, palette=\"viridis\")\n",
        "plt.title('Distribuição da Variável-Alvo (Booking Status)')\n",
        "plt.xlabel('Status da Reserva')\n",
        "plt.ylabel('Contagem')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHKpPI933DYH"
      },
      "outputs": [],
      "source": [
        "# Verificar se há valores duplicados\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjxC2qEwsxRp"
      },
      "outputs": [],
      "source": [
        "# Ver as informações da motivo de cancelamento do motorista\n",
        "df['motivo_cancelamento_motorista'].unique()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCEMZSRV0i1N"
      },
      "source": [
        "## 4. Análise Exploratória dos Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvSW1GvF7Pab"
      },
      "outputs": [],
      "source": [
        "# Analisar a variável motivo cancelamento do motorista\n",
        "df['motivo_cancelamento_motorista'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZgxN0sHIbZw"
      },
      "outputs": [],
      "source": [
        "# Ver as informações da coluna motivo cancelamento do cliente\n",
        "df['motivo_cancelamento_cliente'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xWxBiIF9fx_"
      },
      "outputs": [],
      "source": [
        "# Verificar informações coluna viagens incompletas reason\n",
        "df['viagens_incompletas_reason'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PVoqSYD0CC6"
      },
      "outputs": [],
      "source": [
        "# Criar gráfico lado a lado\n",
        "fig, axes = plt.subplots(1,2, figsize=(18, 8))\n",
        "\n",
        "# Distribuição geral dos do status da reserva\n",
        "sns.countplot(ax=axes[0], x='status_reserva', data=df)\n",
        "axes[0].set_title('1. status da reserva(visão geral)',fontsize=16)\n",
        "axes[0].set_xlabel('status da reserva', fontsize=16)\n",
        "axes[0].set_ylabel('contagem', fontsize=16)\n",
        "\n",
        "# Adicionar rótulos de contagem em cada barra\n",
        "for p in axes[0].patches:\n",
        "    axes[0].annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                     ha='center', va='center', fontsize=11, color='black', xytext=(0, 5),\n",
        "                     textcoords='offset points')\n",
        "\n",
        "# Gráfico 2: Motivos das Corridas Incompletas\n",
        "# Filtrar o DataFrame para incluir apenas corridas com status 'Incomplete'\n",
        "df_incomplete = df[df['status_reserva'] == 'Incomplete']\n",
        "\n",
        "# Obter a contagem dos motivos para o gráfico de pizza\n",
        "motive_counts = df_incomplete['viagens_incompletas_reason'].value_counts()\n",
        "labels = motive_counts.index\n",
        "sizes = motive_counts.values\n",
        "\n",
        "# Criar o gráfico de pizza\n",
        "axes[1].pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('pastel'))\n",
        "axes[1].set_title('2. Motivos de Corridas Incompletas (Análise Detalhada)', fontsize=16)\n",
        "axes[1].axis('equal')  # Garante que o círculo seja perfeito\n",
        "axes[1].legend(title=\"Motivos\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q5fUoAYAeG5"
      },
      "source": [
        "##Insight\n",
        "\n",
        "🚀A plataforma tem um problema de conclusão de corridas, e a causa principal é a falta de motoristas disponíveis ou falhas nos veículos. Esse insight é acionável, pois podemos direcionar as equipes de operações e tecnologia a focar em estratégias para atrair mais motoristas ou melhorar a manutenção da frota, em vez de investir em outras áreas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3cX11Fm0dJA"
      },
      "outputs": [],
      "source": [
        "# Criar os gráficos de box plot lado a lado para comparação\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
        "\n",
        "# Gráfico para a satisfação do cliente\n",
        "sns.boxplot(ax=axes[0], data=df, x='metodo_pagamento', y='avaliacao_cliente')\n",
        "axes[0].set_title('Distribuição das Avaliações de Clientes por Método de Pagamento', fontsize=16)\n",
        "axes[0].set_xlabel('Método de Pagamento', fontsize=12)\n",
        "axes[0].set_ylabel('Avaliação do Cliente', fontsize=12)\n",
        "\n",
        "# Gráfico para a satisfação do motorista\n",
        "sns.boxplot( ax=axes[1], data=df, x='metodo_pagamento', y='avaliacao_motorista')\n",
        "axes[1].set_title('Distribuição das Avaliações de Motoristas por Método de Pagamento', fontsize=16)\n",
        "axes[1].set_xlabel('Método de Pagamento', fontsize=12)\n",
        "axes[1].set_ylabel('Avaliação do Motorista', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFpSRq4JmJYC"
      },
      "outputs": [],
      "source": [
        "# Criar varíável com as colunas númericas para criar gráfico de correlação\n",
        "cols = ['tempo_medio_viagem','tempo_medio_cancelamento','valor_reserva','distancia_viagem','avaliacao_motorista','avaliacao_cliente']\n",
        "\n",
        "#Criar gráfico de correlação\n",
        "sns.heatmap(df[cols].corr(), annot=True, cmap='coolwarm' )\n",
        "plt.title('Correlação entre as variáveis')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6rDaiKaLNVW"
      },
      "outputs": [],
      "source": [
        "# Agrupar os dados e calcular as falhas por localização\n",
        "location_counts = df['local_embarque'].value_counts()\n",
        "top_locations = location_counts.index[:10]\n",
        "\n",
        "# Filtrar o DataFrame para incluir apenas as 10 localizações mais comuns\n",
        "df_top_locations = df[df['local_embarque'].isin(top_locations)]\n",
        "\n",
        "# Calcular a porcentagem de \" motorista não encontrados \" para cada localização\n",
        "location_failure_rate = df_top_locations.groupby('local_embarque')['status_reserva'].apply(\n",
        "    lambda x: (x == 'No Driver Found').mean() * 100\n",
        ").reset_index(name='failure_rate')\n",
        "\n",
        "# Criar gráfico de barras na horizontal\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=location_failure_rate.sort_values(by='failure_rate', ascending=False),\n",
        "            y='local_embarque', x='failure_rate', palette='viridis')\n",
        "plt.title('Taxa de Falha de Encontrar Motorista por Localização(TOP10)', fontsize=16)\n",
        "plt.xlabel('Taxa de Falhas (%)', fontsize=12)\n",
        "plt.ylabel('Localização', fontsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwX_cZW-PlJI"
      },
      "outputs": [],
      "source": [
        "# Vou ontinuar usando o DataFrame df_top_locations da solução anterior lembrando que contem as 10 localizações mais comuns\n",
        "\n",
        "# Limpar a coluna de avaliação do cliente\n",
        "df_top_locations['avaliacao_cliente'].fillna(df_top_locations['avaliacao_cliente'].median(), inplace=True)\n",
        "\n",
        "# Gerar o box plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(data=df_top_locations, x='local_embarque', y='avaliacao_cliente', palette='pastel')\n",
        "\n",
        "plt.title('Distribuição de Avaliações de Clientes por Localização (Top 10)', fontsize=16)\n",
        "plt.xlabel('Local de Partida', fontsize=12)\n",
        "plt.ylabel('Avaliação do Cliente', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right') # Rotaciona os rótulos do eixo x para melhor visualização\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-IutMLHR9JI"
      },
      "outputs": [],
      "source": [
        "# gerar de relatorio de perfil com yprofiling\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "profile = ProfileReport(df, title=\"Dados Uber\")\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LTwEi-lTQqnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY3Wo5tmz7uz"
      },
      "source": [
        "## 5. Modelagem\n",
        "\n",
        "Escolha do modelo preditivo que no caso se tratará de um modelo de classificação simples. O modelo escolhido foi a árvore de decisão para termos um primeiro parametro de como os resultados se comportam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TCBlW90ylgf"
      },
      "outputs": [],
      "source": [
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJPRujM98uP9"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Variáveis que PRECISAM SER REMOVIDAS para evitar o vazamento de dados.\n",
        "LEAKAGE_VARS = ['cancelamentos_cliente', 'cancelamentos_motorista', 'viagens_incompletas']\n",
        "\n",
        "# 1. Definir a lista de features que são CAUSAS, e não RESULTADOS\n",
        "numerical_features_limpas = [\n",
        "    'tempo_medio_viagem', 'tempo_medio_cancelamento', 'valor_reserva', 'distancia_viagem',\n",
        "    'avaliacao_motorista', 'avaliacao_cliente', 'hora' # 'hora' é uma causa legítima\n",
        "]\n",
        "\n",
        "# 2. Definir as colunas categóricas (as mesmas que você usou)\n",
        "categorical_features = ['tipo_veiculo', 'metodo_pagamento', 'local_embarque', 'local_desembarque']\n",
        "\n",
        "# 3. Aplicar One-Hot Encoding\n",
        "# Assumindo que 'df' é o seu DataFrame limpo (sem nulos, com colunas renomeadas)\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# 4. Construir a lista final de features (combinando numéricas limpas e as categóricas)\n",
        "features_limpas = numerical_features_limpas + [\n",
        "    col for col in df_encoded.columns\n",
        "    if col.startswith(tuple(categorical_features)) and col not in LEAKAGE_VARS\n",
        "]\n",
        "\n",
        "X = df_encoded[features_limpas]\n",
        "y = df_encoded['status_reserva']\n",
        "\n",
        "# 5. Dividir e aplicar o SMOTE (o resto do seu código pode ser reaproveitado)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# O treinamento do Random Forest deve ser refeito aqui, usando X_train_smote e y_train_smote\n",
        "# ... (Treinar Random Forest Otimizado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19333bda"
      },
      "outputs": [],
      "source": [
        "# Remover colunas que vazam informação diretamente\n",
        "columns_to_drop_for_leakage = [\n",
        "    'motivo_cancelamento_cliente',\n",
        "    'motivo_cancelamento_motorista',\n",
        "    'viagens_incompletas_reason'\n",
        "]\n",
        "\n",
        "df_cleaned = df.drop(columns=columns_to_drop_for_leakage)\n",
        "\n",
        "print(f\"Colunas removidas: {columns_to_drop_for_leakage}\")\n",
        "print(\"Primeiras linhas do DataFrame após remoção:\")\n",
        "display(df_cleaned.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af0dabe3"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# 1. Criar e treinar o modelo de Regressão Logística\n",
        "# Usamos 'solver='liblinear'' por ser bom para conjuntos de dados menores (embora o seu seja grande, funciona bem)\n",
        "# e para lidar com regularização L1 e L2.\n",
        "logreg_model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "\n",
        "# Treinar o modelo usando os dados de treino balanceados pelo SMOTE\n",
        "print(\"Iniciando treinamento do modelo de Regressão Logística com dados balanceados...\")\n",
        "logreg_model.fit(X_train_smote, y_train_smote)\n",
        "print(\"Treinamento concluído.\")\n",
        "\n",
        "# 2. Fazer previsões no conjunto de TESTE (dados originais, NÃO balanceados)\n",
        "y_pred_logreg = logreg_model.predict(X_test)\n",
        "\n",
        "# 3. Avaliar o modelo\n",
        "print(\"\\n--- Relatório do Modelo de Regressão Logística ---\")\n",
        "print(\"Acurácia Geral do Modelo:\", accuracy_score(y_test, y_pred_logreg))\n",
        "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred_logreg))\n",
        "\n",
        "# Opcional: Matriz de Confusão\n",
        "# print(\"\\nMatriz de Confusão:\\n\", confusion_matrix(y_test, y_pred_logreg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8028yqRvtP6W"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1. Definir o grid de hiperparâmetros para o Random Forest\n",
        "# Usamos um grid menor para otimizar o tempo, mas você pode expandir se quiser mais precisão\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],  # Número de árvores\n",
        "    'max_depth': [10, 20, None], # Profundidade máxima das árvores\n",
        "    'min_samples_split': [5, 10]\n",
        "}\n",
        "\n",
        "# 2. Criar e treinar o GridSearchCV com o Random Forest\n",
        "# O scoring 'recall_macro' é essencial para otimizar o desempenho em todas as classes minoritárias\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "grid_search_rf = GridSearchCV(\n",
        "    estimator=rf_model,\n",
        "    param_grid=param_grid,\n",
        "    cv=2,  # Validação cruzada com 3 folds\n",
        "    scoring='recall_macro',\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Treinar o Grid Search (AGORA COM OS DADOS BALANCEADOS)\n",
        "print(\"\\nIniciando treinamento com dados balanceados...\")\n",
        "grid_search_rf.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "\n",
        "# 3. Avaliar o modelo com os melhores parâmetros\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "\n",
        "# Fazer previsões no conjunto de TESTE (dados originais, NÃO balanceados)\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "# 4. Imprimir os resultados\n",
        "print(\"\\n--- RESULTADOS DA OTIMIZAÇÃO ---\")\n",
        "print(\"Melhores Hiperparâmetros:\", grid_search_rf.best_params_)\n",
        "print(\"Melhor Recall de Validação Cruzada (Macro Avg):\", grid_search_rf.best_score_)\n",
        "\n",
        "print(\"\\n--- Relatório Final do Modelo Random Forest Otimizado ---\")\n",
        "print(\"Acurácia Geral do Modelo:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0DHQaE5XTq_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# O 'best_rf_model' é o modelo Random Forest otimizado do passo anterior\n",
        "# As 'features_limpas' são a lista de variáveis corrigida.\n",
        "\n",
        "# Extrair a importância das variáveis\n",
        "importances = best_rf_model.feature_importances_\n",
        "\n",
        "# Criar uma Series do Pandas para organizar e nomear\n",
        "feature_importances = pd.Series(importances, index=features_limpas).sort_values(ascending=False)\n",
        "\n",
        "# Visualizar as TOP 10 Variáveis mais importantes\n",
        "plt.figure(figsize=(14, 8))\n",
        "# Usamos .head(10) para focar nas mais relevantes\n",
        "sns.barplot(x=feature_importances.head(10).values, y=feature_importances.head(10).index, palette=\"mako\")\n",
        "plt.title('Importância das Variáveis no Modelo Random Forest Limpo')\n",
        "plt.xlabel('Pontuação de Importância')\n",
        "plt.ylabel('Variáveis')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Imprimir a lista final para análise\n",
        "print(\"\\n--- TOP 10 Variáveis Mais Importantes ---\")\n",
        "print(feature_importances.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "importances = best_rf_model.feature_importances_\n",
        "\n",
        "feature_importances = pd.Series(importances, index=features_limpas).sort_values(ascending=False)\n",
        "\n",
        "# 3. Visualizar as TOP 10 Variáveis mais importantes\n",
        "plt.figure(figsize=(14, 8))\n",
        "# Usamos .head(10) para focar nas mais relevantes\n",
        "sns.barplot(x=feature_importances.head(10).values, y=feature_importances.head(10).index, palette=\"mako\")\n",
        "plt.title('TOP 10 Fatores de Decisão no Modelo Random Forest Limpo')\n",
        "plt.xlabel('Pontuação de Importância')\n",
        "plt.ylabel('Variáveis')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4. Imprimir a lista final para análise\n",
        "print(\"\\n--- TOP 10 VARIÁVEIS MAIS IMPORTANTES ---\")\n",
        "print(feature_importances.head(10))"
      ],
      "metadata": {
        "id": "csyodJtEJn8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusão do modelo de forma detalhada\n",
        "\n",
        "1.\n",
        "\n",
        "Respondendo à Pergunta de Negócio\n",
        "Pergunta: Quais fatores influenciam a chance de uma corrida ser cancelada por um motorista ou cliente?\n",
        "\n",
        "Resposta Baseada no Modelo Otimizado (Random Forest):\n",
        "\n",
        "O modelo identificou que a duração potencial da viagem e a experiência do cliente são os principais determinantes do status final de uma reserva, influenciando diretamente a probabilidade de um cancelamento ou não.\n",
        "\n",
        "A variável mais crucial (com uma importância de 32,46%) é o tempo_medio_viagem. Isso demonstra que, no momento da reserva, o fator decisivo para a conclusão da corrida é o quão longo o trajeto é esperado. Corridas mais longas, que prendem o motorista por mais tempo, ou corridas mais curtas em áreas de pico, representam um risco maior de rejeição ou cancelamento.\n",
        "\n",
        "O segundo fator mais importante é a qualidade do cliente, medida pela avaliacao_cliente (7,87%), indicando que a percepção de risco ou do histórico do passageiro é um forte preditor de cancelamento.\n",
        "\n",
        "2.\n",
        "\n",
        "Extraindo Insights Acionáveis para a Empresa\n",
        "Os resultados do modelo de Machine Learning traduzem-se diretamente em quatro pilares de ação para o negócio:\n",
        "\n",
        "Ação 1: Foco na Duração e Distância da Viagem (Otimização da Rota)\n",
        "Insight: As variáveis tempo_medio_viagem (32.46%) e distancia_viagem (8.94%) são, juntas, responsáveis por mais de 41% da decisão do modelo.\n",
        "\n",
        "Ação Acionável: A empresa deve criar um incentivo dinâmico para motoristas aceitarem corridas com alto tempo_medio_viagem. Isso pode ser um bônus por aceitação ou uma garantia de que a próxima corrida será próxima ao ponto de desembarque final.\n",
        "\n",
        "Ação 2: Gerenciamento Ativo da Qualidade do Cliente (Risco)\n",
        "Insight: A avaliacao_cliente (7.87%) é mais importante do que o tempo_medio_cancelamento e o valor_reserva.\n",
        "\n",
        "Ação Acionável: O modelo deve ser integrado a um sistema de priorização: clientes com avaliações abaixo de, por exemplo, 4.5 devem ter suas solicitações de reserva enviadas com um pequeno bônus adicional para o motorista, reduzindo a chance de rejeição inicial.\n",
        "\n",
        "Ação 3: Auditoria do Tempo de Espera e Avaliação do Motorista\n",
        "Insight: O tempo_medio_cancelamento (6.79%) e a avaliacao_motorista (6.50%) são fatores humanos cruciais.\n",
        "\n",
        "Ação Acionável: Implementar um alerta para a equipe de operações quando o tempo_medio_cancelamento ultrapassar um certo limite (por exemplo, 5 minutos), pois isso é um sinal de alto risco de cancelamento subsequente. Paralelamente, planos de melhoria de qualidade devem ser focados em motoristas com avaliações abaixo de 4.5.\n",
        "\n",
        "Ação 4: Simplificação e Transparência de Pagamento\n",
        "Insight: O metodo_pagamento_Desconhecido (8.51%) é o terceiro fator mais importante.\n",
        "\n",
        "Ação Acionável: A alta importância de métodos desconhecidos sugere que a falta de clareza sobre como a corrida será paga gera incerteza para o motorista ou cliente, aumentando o risco de cancelamento. A empresa deve simplificar e garantir a máxima transparência sobre o método de pagamento no momento da reserva.\n",
        "\n",
        "3.\n",
        "\n",
        "Conclusão Final do Projeto\n",
        "O projeto é um exemplo de ciclo completo da Ciência de Dados:\n",
        "\n",
        "Limpeza de Dados: Tratou nulos e fez o One-Hot Encoding.\n",
        "\n",
        "Detecção de Falhas: Corrigiu o grave Data Leakage que inflacionava a acurácia.\n",
        "\n",
        "Otimização: Usou o SMOTE para balancear classes e o Random Forest para robustez.\n",
        "\n",
        "Entrega de Valor: O modelo final, agora limpo e interpretável, provê um mapa claro de onde a empresa deve concentrar seus recursos (focando em Tempo de Viagem e Qualidade do Cliente), maximizando a chance de uma corrida ser concluída."
      ],
      "metadata": {
        "id": "4-ZSvoeMSRil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusão Final do Projeto: Otimização de Classificação de Reservas\n",
        "O projeto iniciou-se com a Regressão Logística como baseline (acurácia de 81%) e revelou que as classes minoritárias, como No Driver Found, eram mal previstas. O principal avanço foi a transição metodológica para um modelo de ponta, corrigindo falhas graves no processo.\n",
        "\n",
        "Primeiro, foi fundamental a correção de Vazamento de Dados (Data Leakage), garantindo que o modelo fizesse uma previsão real e não uma consulta. Em seguida, a técnica de SMOTE foi aplicada para balancear as classes minoritárias no conjunto de treino. Esta base otimizada foi utilizada para treinar um modelo Random Forest, um método de Ensemble Learning, que teve sua performance maximizada via GridSearchCV (ajuste de hiperparâmetros).\n",
        "\n",
        "O resultado final foi um modelo com 94% de acurácia, que elevou drasticamente o Recall para classes críticas (ex: No Driver Found de 30% para 100%). A análise de Feature Importance concluiu que a duração da viagem é o principal fator preditor, fornecendo o insight acionável definitivo para o negócio. O projeto valida a eficácia de modelos complexos e a importância de técnicas avançadas para a geração de valor."
      ],
      "metadata": {
        "id": "z1v_sCKODVZu"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4aJ6bcPLybcRvmZ/f/S+N",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}