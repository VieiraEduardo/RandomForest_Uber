{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VieiraEduardo/RandomForest_Uber/blob/main/RandomForestUber.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii07CyguSaie"
      },
      "source": [
        "## Pipeline de Ci√™ncia de Dados ##\n",
        "\n",
        "√â importante definir todas as fases de cria√ß√£o de cria√ß√£o de um projeto que envolve Ci√™ncias de Dados, para detectar o problema de neg√≥cio e o objetivo desejado de forma eficiente.\n",
        "\n",
        "1.Problema de Neg√≥cio\n",
        "\n",
        "Prever o cancelamento das viagens que √© a classifica√ß√£o de status da reserva.\n",
        "\n",
        "2.Coleta e armasentamento de dados\n",
        "\n",
        "Dados adquiridos do Kaggle\n",
        "\n",
        "3.Pr√© Processamento e limpeza dos dados\n",
        "\n",
        "4.Analise Explorat√≥ria dos Dados\n",
        "\n",
        "5.Modelagem\n",
        "\n",
        "6.Avalia√ß√£o de Modelo\n",
        "\n",
        "7.Interpreta√ß√£o e comunica√ß√£o dos resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WY3tqBtXQ-Z8"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas a utilizar\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "373545c5"
      },
      "outputs": [],
      "source": [
        "!pip install ydata-profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ9fMaMRURz9"
      },
      "outputs": [],
      "source": [
        "# Carregar e ler dataset\n",
        "df = pd.read_csv('/content/ncr_ride_bookings.csv', index_col='Customer ID')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5qFiTl8RKQS"
      },
      "outputs": [],
      "source": [
        "# Verificar informa√ß√µes do dataset\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "181wtj1A1W67"
      },
      "source": [
        "## 3. Pr√© Processamento e Limpeza dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCJHvKRChXDP"
      },
      "outputs": [],
      "source": [
        "# 2. Assegurar que as colunas 'Date' e 'Time' s√£o do tipo string para evitar erros.\n",
        "df['Date'] = df['Date'].astype(str)\n",
        "df['Time'] = df['Time'].astype(str)\n",
        "\n",
        "# 3. Combinar as colunas 'Date' e 'Time' em uma √∫nica coluna 'DateTime'.\n",
        "df['DateTime'] = df['Date'] + ' ' + df['Time']\n",
        "\n",
        "# 4. Converter a nova coluna 'DateTime' para o tipo datetime.\n",
        "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
        "\n",
        "# 5. (Opcional) Criar novas colunas para an√°lise, como o dia da semana.\n",
        "df['DayOfWeek'] = df['DateTime'].dt.day_name()\n",
        "df['Hour'] = df['DateTime'].dt.hour\n",
        "\n",
        "#Excluir coluna Date e coluna Time\n",
        "df.drop(['Date', 'Time'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5E1eT0yh02i"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6ULyAX2rhro"
      },
      "outputs": [],
      "source": [
        "# Alinhar cabe√ßalho do df\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcywZBeFAKW0"
      },
      "outputs": [],
      "source": [
        "# Remover primeira linha n√£o mais necess√°ria\n",
        "df.drop(df.index[0], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ew1uIYXs0ZjN"
      },
      "outputs": [],
      "source": [
        "# Verificar linhas do dataset de forma aleatoria\n",
        "df.sample(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oTx2DK_YGLW"
      },
      "outputs": [],
      "source": [
        "# verificar as colunas que contem dados nulos\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2O4yYZ1pyO1"
      },
      "source": [
        "##Observa√ß√£o\n",
        "\n",
        "√â perceptivel que mais da metade das colunas tem valores nulos/sem informa√ß√£o, isso para um modelo preditivo pode enviesar o modelo se n√£o bem tratado. √â necess√°rio entender se aqueles valores realmente tem ou n√£o informa√ß√£o √∫teis, ou se n√£o foram devidadamente preenchidos na hora da aquisi√ß√£o do Banco de Dados.\n",
        "Para melhor visualiza√ß√£o e compreens√£o, colocar os valores null em porcetagem que d√° um no√ß√£o melhor se d√° para trabalhar com determinada coluna.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-y_kmn_nLoV"
      },
      "outputs": [],
      "source": [
        "# Verificar quantos por % de dados nulos tem em cada coluna do Dataframe\n",
        "(df.isnull().sum()/df.shape[0])*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kL4DdQo6Ql3"
      },
      "source": [
        "##Observa√ß√£o\n",
        "\n",
        "Colunas com mais de 50% dos dados ausentes, ap√≥s interpreta√ß√£o com o modelo de neg√≥cio, podem ser consideradas a se serem excluidas. Colunas com baixa porcentagem, seja at√© 10% ou 20% podemos realizar algumas tecnicas de imputa√ß√£o para tentar preencher esses valores ausentes.\n",
        "\n",
        "As colunas Driver Ratings e Customer Rating haviam 38% de dados ausentes, onde optei por fazer uma imputa√ß√£o pela mediana que √© uma estrat√©gia robusta aos valores da coluna e n√£o distorce a distribui√ß√£o dos dados, preservando e retendo o m√°ximo de informa√ß√£o.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gFGVsKyAgvy3"
      },
      "outputs": [],
      "source": [
        "# substituir dados nan da coluna Driver Rating pela Mediana\n",
        "df['driver_ratings'].fillna(df['driver_ratings'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wwd1cqo7_i3"
      },
      "outputs": [],
      "source": [
        "# substituir dados nan da coluna Customer Rating pela Mediana\n",
        "df['customer_rating'].fillna(df['customer_rating'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KliDN7OM_DKK"
      },
      "source": [
        "## Oberserva√ß√£o\n",
        "\n",
        "Existem 4 colunas com mais de 80% com dados nulos. Cancelled Rides by Customer e reason for cancelling by customer\t(93%) e Reason for cancelled rides by driver  e Driver Cancellation Reason (82%).\n",
        "\n",
        "Ideal fazer uma imputa√ß√£o de dados onde optei pela seguinte estrat√©gia:\n",
        "\n",
        "##Para Cancelled Rides by Customer e Cancelled Rides by Driver:\n",
        "\n",
        "Substituir os valores nulos por 0.\n",
        "\n",
        "Onde j√° existe o valor 1, eu os mantenho-o.\n",
        "\n",
        "O resulto obtido ser√° uma vari√°vel bin√°ria (0 ou 1) que indica se o cancelamento partiu do motorista ou do cliente. Isso √© perfeito para um modelo de classifica√ß√£o.\n",
        "\n",
        "##Para Reason for cancelling by Customer e Driver Cancellation Reason:\n",
        "\n",
        "Substituir os valores nulos por uma categoria como \"N√£o se Aplica\" ou \"Corrida Conclu√≠da\".\n",
        "\n",
        "Aos motivos de cancelamento existentes, como \"Vehicle Breakdown\". eu os mantenho-o.\n",
        "\n",
        "O resultado obtido ser√° uma vari√°vel categ√≥rica que informa o motivo do cancelamento, o que pode ser um recurso valioso para o modelo entender o comportamento de clientes e motoristas.\n",
        "\n",
        "Ao fazer isso, eu n√£o apenas preservo os dados, mas tamb√©m crio vari√°veis poderosas com informa√ß√£o robusta que ser√£o a base do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiaM7sQR9Zlp"
      },
      "outputs": [],
      "source": [
        "# Substituir os valores nulos da coluna Cancelled Rides by Costumer e Cancelled Rides bu Driver\n",
        "df['cancelled_rides_by_customer'].fillna(0, inplace=True)\n",
        "df['cancelled_rides_by_driver'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0jgNyUMDl3C"
      },
      "outputs": [],
      "source": [
        "# Substituir os valores nulos da coluna Cancelling by Customer e Driver Cancellation Reason por uma categoria N√£o se Aplica ou Corrida concluida\n",
        "df['reason_for_cancelling_by_customer'].fillna(' N√£o Se Aplica', inplace=True)\n",
        "df['driver_cancellation_reason'].fillna('N√£o Se Aplica', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEvC7WA0fOW7"
      },
      "outputs": [],
      "source": [
        "# Substituir dados das colunas avg_vtat, avg_ctat, booking value, Ride Distance pela mediana\n",
        "df['avg_vtat'].fillna(df['avg_vtat'].median(), inplace=True)\n",
        "df['avg_ctat'].fillna(df['avg_ctat'].median(), inplace=True)\n",
        "df['booking_value'].fillna(df['booking_value'].median(), inplace=True)\n",
        "df['ride_distance'].fillna(df['ride_distance'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF34Ra7ssFkr"
      },
      "outputs": [],
      "source": [
        "# Substituir os valores NAN da coluna imcomplete rides por 0\n",
        "df['incomplete_rides'].fillna(0, inplace=True)\n",
        "\n",
        "#Substituir os valores NAN da coluna Imcomplete rides reason por n√£o se aplica\n",
        "df['incomplete_rides_reason'].fillna('N√£o Se Aplica', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cK3viiKN_Nwn"
      },
      "outputs": [],
      "source": [
        "# Substituir valores NAN da coluna Payment Method por Desconhecido\n",
        "df['payment_method'].fillna('Desconhecido', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrjR9s6C6DwQ"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiZ90umjwJrn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RvrkBafI055"
      },
      "outputs": [],
      "source": [
        "# Traduzir o nome de todas as colunas\n",
        "df.columns = df.columns.str.replace('booking_id', 'id_reserva')\n",
        "df.columns = df.columns.str.replace('booking_status', 'status_reserva')\n",
        "df.columns = df.columns.str.replace('vehicle_type', 'tipo_veiculo')\n",
        "df.columns = df.columns.str.replace('pickup_location', 'local_embarque')\n",
        "df.columns = df.columns.str.replace('drop_location', 'local_desembarque')\n",
        "df.columns = df.columns.str.replace('avg_vtat', 'tempo_medio_viagem')\n",
        "df.columns = df.columns.str.replace('avg_ctat', 'tempo_medio_cancelamento')\n",
        "df.columns = df.columns.str.replace('cancelled_rides_by_customer', 'cancelamentos_cliente')\n",
        "df.columns = df.columns.str.replace('reason_for_cancelling_by_customer', 'motivo_cancelamento_cliente')\n",
        "df.columns = df.columns.str.replace('cancelled_rides_by_driver', 'cancelamentos_motorista')\n",
        "df.columns = df.columns.str.replace('driver_cancellation_reason', 'motivo_cancelamento_motorista')\n",
        "df.columns = df.columns.str.replace('incomplete_rides', 'viagens_incompletas')\n",
        "df.columns = df.columns.str.replace('incomplete_rides_reason', 'motivo_viagens_incompletas')\n",
        "df.columns = df.columns.str.replace('booking_value', 'valor_reserva')\n",
        "df.columns = df.columns.str.replace('ride_distance', 'distancia_viagem')\n",
        "df.columns = df.columns.str.replace('driver_ratings', 'avaliacao_motorista')\n",
        "df.columns = df.columns.str.replace('customer_rating', 'avaliacao_cliente')\n",
        "df.columns = df.columns.str.replace('payment_method', 'metodo_pagamento')\n",
        "df.columns = df.columns.str.replace('datetime', 'data_hora')\n",
        "df.columns = df.columns.str.replace('dayofweek', 'dia_semana')\n",
        "df.columns = df.columns.str.replace('hour', 'hora')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Zloel0uIhfs"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsVrHiRP5JQE"
      },
      "outputs": [],
      "source": [
        "# 1. Calcular a distribui√ß√£o e o percentual da vari√°vel-alvo\n",
        "status_counts = df['status_reserva'].value_counts()\n",
        "status_percentages = df['status_reserva'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"--- Distribui√ß√£o Num√©rica do Booking Status ---\")\n",
        "print(pd.DataFrame({'Contagem': status_counts, 'Percentual': status_percentages.round(2).astype(str) + '%'}))\n",
        "\n",
        "# 3. Visualizar a distribui√ß√£o (Gr√°fico de Barras)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=status_counts.index, y=status_counts.values, palette=\"viridis\")\n",
        "plt.title('Distribui√ß√£o da Vari√°vel-Alvo (Booking Status)')\n",
        "plt.xlabel('Status da Reserva')\n",
        "plt.ylabel('Contagem')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHKpPI933DYH"
      },
      "outputs": [],
      "source": [
        "# Verificar se h√° valores duplicados\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjxC2qEwsxRp"
      },
      "outputs": [],
      "source": [
        "# Ver as informa√ß√µes da motivo de cancelamento do motorista\n",
        "df['motivo_cancelamento_motorista'].unique()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCEMZSRV0i1N"
      },
      "source": [
        "## 4. An√°lise Explorat√≥ria dos Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvSW1GvF7Pab"
      },
      "outputs": [],
      "source": [
        "# Analisar a vari√°vel motivo cancelamento do motorista\n",
        "df['motivo_cancelamento_motorista'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZgxN0sHIbZw"
      },
      "outputs": [],
      "source": [
        "# Ver as informa√ß√µes da coluna motivo cancelamento do cliente\n",
        "df['motivo_cancelamento_cliente'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xWxBiIF9fx_"
      },
      "outputs": [],
      "source": [
        "# Verificar informa√ß√µes coluna viagens incompletas reason\n",
        "df['viagens_incompletas_reason'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PVoqSYD0CC6"
      },
      "outputs": [],
      "source": [
        "# Criar gr√°fico lado a lado\n",
        "fig, axes = plt.subplots(1,2, figsize=(18, 8))\n",
        "\n",
        "# Distribui√ß√£o geral dos do status da reserva\n",
        "sns.countplot(ax=axes[0], x='status_reserva', data=df)\n",
        "axes[0].set_title('1. status da reserva(vis√£o geral)',fontsize=16)\n",
        "axes[0].set_xlabel('status da reserva', fontsize=16)\n",
        "axes[0].set_ylabel('contagem', fontsize=16)\n",
        "\n",
        "# Adicionar r√≥tulos de contagem em cada barra\n",
        "for p in axes[0].patches:\n",
        "    axes[0].annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                     ha='center', va='center', fontsize=11, color='black', xytext=(0, 5),\n",
        "                     textcoords='offset points')\n",
        "\n",
        "# Gr√°fico 2: Motivos das Corridas Incompletas\n",
        "# Filtrar o DataFrame para incluir apenas corridas com status 'Incomplete'\n",
        "df_incomplete = df[df['status_reserva'] == 'Incomplete']\n",
        "\n",
        "# Obter a contagem dos motivos para o gr√°fico de pizza\n",
        "motive_counts = df_incomplete['viagens_incompletas_reason'].value_counts()\n",
        "labels = motive_counts.index\n",
        "sizes = motive_counts.values\n",
        "\n",
        "# Criar o gr√°fico de pizza\n",
        "axes[1].pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('pastel'))\n",
        "axes[1].set_title('2. Motivos de Corridas Incompletas (An√°lise Detalhada)', fontsize=16)\n",
        "axes[1].axis('equal')  # Garante que o c√≠rculo seja perfeito\n",
        "axes[1].legend(title=\"Motivos\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q5fUoAYAeG5"
      },
      "source": [
        "##Insight\n",
        "\n",
        "üöÄA plataforma tem um problema de conclus√£o de corridas, e a causa principal √© a falta de motoristas dispon√≠veis ou falhas nos ve√≠culos. Esse insight √© acion√°vel, pois podemos direcionar as equipes de opera√ß√µes e tecnologia a focar em estrat√©gias para atrair mais motoristas ou melhorar a manuten√ß√£o da frota, em vez de investir em outras √°reas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3cX11Fm0dJA"
      },
      "outputs": [],
      "source": [
        "# Criar os gr√°ficos de box plot lado a lado para compara√ß√£o\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
        "\n",
        "# Gr√°fico para a satisfa√ß√£o do cliente\n",
        "sns.boxplot(ax=axes[0], data=df, x='metodo_pagamento', y='avaliacao_cliente')\n",
        "axes[0].set_title('Distribui√ß√£o das Avalia√ß√µes de Clientes por M√©todo de Pagamento', fontsize=16)\n",
        "axes[0].set_xlabel('M√©todo de Pagamento', fontsize=12)\n",
        "axes[0].set_ylabel('Avalia√ß√£o do Cliente', fontsize=12)\n",
        "\n",
        "# Gr√°fico para a satisfa√ß√£o do motorista\n",
        "sns.boxplot( ax=axes[1], data=df, x='metodo_pagamento', y='avaliacao_motorista')\n",
        "axes[1].set_title('Distribui√ß√£o das Avalia√ß√µes de Motoristas por M√©todo de Pagamento', fontsize=16)\n",
        "axes[1].set_xlabel('M√©todo de Pagamento', fontsize=12)\n",
        "axes[1].set_ylabel('Avalia√ß√£o do Motorista', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFpSRq4JmJYC"
      },
      "outputs": [],
      "source": [
        "# Criar var√≠√°vel com as colunas n√∫mericas para criar gr√°fico de correla√ß√£o\n",
        "cols = ['tempo_medio_viagem','tempo_medio_cancelamento','valor_reserva','distancia_viagem','avaliacao_motorista','avaliacao_cliente']\n",
        "\n",
        "#Criar gr√°fico de correla√ß√£o\n",
        "sns.heatmap(df[cols].corr(), annot=True, cmap='coolwarm' )\n",
        "plt.title('Correla√ß√£o entre as vari√°veis')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6rDaiKaLNVW"
      },
      "outputs": [],
      "source": [
        "# Agrupar os dados e calcular as falhas por localiza√ß√£o\n",
        "location_counts = df['local_embarque'].value_counts()\n",
        "top_locations = location_counts.index[:10]\n",
        "\n",
        "# Filtrar o DataFrame para incluir apenas as 10 localiza√ß√µes mais comuns\n",
        "df_top_locations = df[df['local_embarque'].isin(top_locations)]\n",
        "\n",
        "# Calcular a porcentagem de \" motorista n√£o encontrados \" para cada localiza√ß√£o\n",
        "location_failure_rate = df_top_locations.groupby('local_embarque')['status_reserva'].apply(\n",
        "    lambda x: (x == 'No Driver Found').mean() * 100\n",
        ").reset_index(name='failure_rate')\n",
        "\n",
        "# Criar gr√°fico de barras na horizontal\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=location_failure_rate.sort_values(by='failure_rate', ascending=False),\n",
        "            y='local_embarque', x='failure_rate', palette='viridis')\n",
        "plt.title('Taxa de Falha de Encontrar Motorista por Localiza√ß√£o(TOP10)', fontsize=16)\n",
        "plt.xlabel('Taxa de Falhas (%)', fontsize=12)\n",
        "plt.ylabel('Localiza√ß√£o', fontsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwX_cZW-PlJI"
      },
      "outputs": [],
      "source": [
        "# Vou ontinuar usando o DataFrame df_top_locations da solu√ß√£o anterior lembrando que contem as 10 localiza√ß√µes mais comuns\n",
        "\n",
        "# Limpar a coluna de avalia√ß√£o do cliente\n",
        "df_top_locations['avaliacao_cliente'].fillna(df_top_locations['avaliacao_cliente'].median(), inplace=True)\n",
        "\n",
        "# Gerar o box plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(data=df_top_locations, x='local_embarque', y='avaliacao_cliente', palette='pastel')\n",
        "\n",
        "plt.title('Distribui√ß√£o de Avalia√ß√µes de Clientes por Localiza√ß√£o (Top 10)', fontsize=16)\n",
        "plt.xlabel('Local de Partida', fontsize=12)\n",
        "plt.ylabel('Avalia√ß√£o do Cliente', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right') # Rotaciona os r√≥tulos do eixo x para melhor visualiza√ß√£o\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-IutMLHR9JI"
      },
      "outputs": [],
      "source": [
        "# gerar de relatorio de perfil com yprofiling\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "profile = ProfileReport(df, title=\"Dados Uber\")\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LTwEi-lTQqnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY3Wo5tmz7uz"
      },
      "source": [
        "## 5. Modelagem\n",
        "\n",
        "Escolha do modelo preditivo que no caso se tratar√° de um modelo de classifica√ß√£o simples. O modelo escolhido foi a √°rvore de decis√£o para termos um primeiro parametro de como os resultados se comportam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TCBlW90ylgf"
      },
      "outputs": [],
      "source": [
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJPRujM98uP9"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Vari√°veis que PRECISAM SER REMOVIDAS para evitar o vazamento de dados.\n",
        "LEAKAGE_VARS = ['cancelamentos_cliente', 'cancelamentos_motorista', 'viagens_incompletas']\n",
        "\n",
        "# 1. Definir a lista de features que s√£o CAUSAS, e n√£o RESULTADOS\n",
        "numerical_features_limpas = [\n",
        "    'tempo_medio_viagem', 'tempo_medio_cancelamento', 'valor_reserva', 'distancia_viagem',\n",
        "    'avaliacao_motorista', 'avaliacao_cliente', 'hora' # 'hora' √© uma causa leg√≠tima\n",
        "]\n",
        "\n",
        "# 2. Definir as colunas categ√≥ricas (as mesmas que voc√™ usou)\n",
        "categorical_features = ['tipo_veiculo', 'metodo_pagamento', 'local_embarque', 'local_desembarque']\n",
        "\n",
        "# 3. Aplicar One-Hot Encoding\n",
        "# Assumindo que 'df' √© o seu DataFrame limpo (sem nulos, com colunas renomeadas)\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# 4. Construir a lista final de features (combinando num√©ricas limpas e as categ√≥ricas)\n",
        "features_limpas = numerical_features_limpas + [\n",
        "    col for col in df_encoded.columns\n",
        "    if col.startswith(tuple(categorical_features)) and col not in LEAKAGE_VARS\n",
        "]\n",
        "\n",
        "X = df_encoded[features_limpas]\n",
        "y = df_encoded['status_reserva']\n",
        "\n",
        "# 5. Dividir e aplicar o SMOTE (o resto do seu c√≥digo pode ser reaproveitado)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# O treinamento do Random Forest deve ser refeito aqui, usando X_train_smote e y_train_smote\n",
        "# ... (Treinar Random Forest Otimizado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19333bda"
      },
      "outputs": [],
      "source": [
        "# Remover colunas que vazam informa√ß√£o diretamente\n",
        "columns_to_drop_for_leakage = [\n",
        "    'motivo_cancelamento_cliente',\n",
        "    'motivo_cancelamento_motorista',\n",
        "    'viagens_incompletas_reason'\n",
        "]\n",
        "\n",
        "df_cleaned = df.drop(columns=columns_to_drop_for_leakage)\n",
        "\n",
        "print(f\"Colunas removidas: {columns_to_drop_for_leakage}\")\n",
        "print(\"Primeiras linhas do DataFrame ap√≥s remo√ß√£o:\")\n",
        "display(df_cleaned.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af0dabe3"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# 1. Criar e treinar o modelo de Regress√£o Log√≠stica\n",
        "# Usamos 'solver='liblinear'' por ser bom para conjuntos de dados menores (embora o seu seja grande, funciona bem)\n",
        "# e para lidar com regulariza√ß√£o L1 e L2.\n",
        "logreg_model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "\n",
        "# Treinar o modelo usando os dados de treino balanceados pelo SMOTE\n",
        "print(\"Iniciando treinamento do modelo de Regress√£o Log√≠stica com dados balanceados...\")\n",
        "logreg_model.fit(X_train_smote, y_train_smote)\n",
        "print(\"Treinamento conclu√≠do.\")\n",
        "\n",
        "# 2. Fazer previs√µes no conjunto de TESTE (dados originais, N√ÉO balanceados)\n",
        "y_pred_logreg = logreg_model.predict(X_test)\n",
        "\n",
        "# 3. Avaliar o modelo\n",
        "print(\"\\n--- Relat√≥rio do Modelo de Regress√£o Log√≠stica ---\")\n",
        "print(\"Acur√°cia Geral do Modelo:\", accuracy_score(y_test, y_pred_logreg))\n",
        "print(\"\\nRelat√≥rio de Classifica√ß√£o:\\n\", classification_report(y_test, y_pred_logreg))\n",
        "\n",
        "# Opcional: Matriz de Confus√£o\n",
        "# print(\"\\nMatriz de Confus√£o:\\n\", confusion_matrix(y_test, y_pred_logreg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8028yqRvtP6W"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1. Definir o grid de hiperpar√¢metros para o Random Forest\n",
        "# Usamos um grid menor para otimizar o tempo, mas voc√™ pode expandir se quiser mais precis√£o\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],  # N√∫mero de √°rvores\n",
        "    'max_depth': [10, 20, None], # Profundidade m√°xima das √°rvores\n",
        "    'min_samples_split': [5, 10]\n",
        "}\n",
        "\n",
        "# 2. Criar e treinar o GridSearchCV com o Random Forest\n",
        "# O scoring 'recall_macro' √© essencial para otimizar o desempenho em todas as classes minorit√°rias\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "grid_search_rf = GridSearchCV(\n",
        "    estimator=rf_model,\n",
        "    param_grid=param_grid,\n",
        "    cv=2,  # Valida√ß√£o cruzada com 3 folds\n",
        "    scoring='recall_macro',\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Treinar o Grid Search (AGORA COM OS DADOS BALANCEADOS)\n",
        "print(\"\\nIniciando treinamento com dados balanceados...\")\n",
        "grid_search_rf.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "\n",
        "# 3. Avaliar o modelo com os melhores par√¢metros\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "\n",
        "# Fazer previs√µes no conjunto de TESTE (dados originais, N√ÉO balanceados)\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "# 4. Imprimir os resultados\n",
        "print(\"\\n--- RESULTADOS DA OTIMIZA√á√ÉO ---\")\n",
        "print(\"Melhores Hiperpar√¢metros:\", grid_search_rf.best_params_)\n",
        "print(\"Melhor Recall de Valida√ß√£o Cruzada (Macro Avg):\", grid_search_rf.best_score_)\n",
        "\n",
        "print(\"\\n--- Relat√≥rio Final do Modelo Random Forest Otimizado ---\")\n",
        "print(\"Acur√°cia Geral do Modelo:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nRelat√≥rio de Classifica√ß√£o:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0DHQaE5XTq_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# O 'best_rf_model' √© o modelo Random Forest otimizado do passo anterior\n",
        "# As 'features_limpas' s√£o a lista de vari√°veis corrigida.\n",
        "\n",
        "# Extrair a import√¢ncia das vari√°veis\n",
        "importances = best_rf_model.feature_importances_\n",
        "\n",
        "# Criar uma Series do Pandas para organizar e nomear\n",
        "feature_importances = pd.Series(importances, index=features_limpas).sort_values(ascending=False)\n",
        "\n",
        "# Visualizar as TOP 10 Vari√°veis mais importantes\n",
        "plt.figure(figsize=(14, 8))\n",
        "# Usamos .head(10) para focar nas mais relevantes\n",
        "sns.barplot(x=feature_importances.head(10).values, y=feature_importances.head(10).index, palette=\"mako\")\n",
        "plt.title('Import√¢ncia das Vari√°veis no Modelo Random Forest Limpo')\n",
        "plt.xlabel('Pontua√ß√£o de Import√¢ncia')\n",
        "plt.ylabel('Vari√°veis')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Imprimir a lista final para an√°lise\n",
        "print(\"\\n--- TOP 10 Vari√°veis Mais Importantes ---\")\n",
        "print(feature_importances.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "importances = best_rf_model.feature_importances_\n",
        "\n",
        "feature_importances = pd.Series(importances, index=features_limpas).sort_values(ascending=False)\n",
        "\n",
        "# 3. Visualizar as TOP 10 Vari√°veis mais importantes\n",
        "plt.figure(figsize=(14, 8))\n",
        "# Usamos .head(10) para focar nas mais relevantes\n",
        "sns.barplot(x=feature_importances.head(10).values, y=feature_importances.head(10).index, palette=\"mako\")\n",
        "plt.title('TOP 10 Fatores de Decis√£o no Modelo Random Forest Limpo')\n",
        "plt.xlabel('Pontua√ß√£o de Import√¢ncia')\n",
        "plt.ylabel('Vari√°veis')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4. Imprimir a lista final para an√°lise\n",
        "print(\"\\n--- TOP 10 VARI√ÅVEIS MAIS IMPORTANTES ---\")\n",
        "print(feature_importances.head(10))"
      ],
      "metadata": {
        "id": "csyodJtEJn8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclus√£o do modelo de forma detalhada\n",
        "\n",
        "1.\n",
        "\n",
        "Respondendo √† Pergunta de Neg√≥cio\n",
        "Pergunta: Quais fatores influenciam a chance de uma corrida ser cancelada por um motorista ou cliente?\n",
        "\n",
        "Resposta Baseada no Modelo Otimizado (Random Forest):\n",
        "\n",
        "O modelo identificou que a dura√ß√£o potencial da viagem e a experi√™ncia do cliente s√£o os principais determinantes do status final de uma reserva, influenciando diretamente a probabilidade de um cancelamento ou n√£o.\n",
        "\n",
        "A vari√°vel mais crucial (com uma import√¢ncia de 32,46%) √© o tempo_medio_viagem. Isso demonstra que, no momento da reserva, o fator decisivo para a conclus√£o da corrida √© o qu√£o longo o trajeto √© esperado. Corridas mais longas, que prendem o motorista por mais tempo, ou corridas mais curtas em √°reas de pico, representam um risco maior de rejei√ß√£o ou cancelamento.\n",
        "\n",
        "O segundo fator mais importante √© a qualidade do cliente, medida pela avaliacao_cliente (7,87%), indicando que a percep√ß√£o de risco ou do hist√≥rico do passageiro √© um forte preditor de cancelamento.\n",
        "\n",
        "2.\n",
        "\n",
        "Extraindo Insights Acion√°veis para a Empresa\n",
        "Os resultados do modelo de Machine Learning traduzem-se diretamente em quatro pilares de a√ß√£o para o neg√≥cio:\n",
        "\n",
        "A√ß√£o 1: Foco na Dura√ß√£o e Dist√¢ncia da Viagem (Otimiza√ß√£o da Rota)\n",
        "Insight: As vari√°veis tempo_medio_viagem (32.46%) e distancia_viagem (8.94%) s√£o, juntas, respons√°veis por mais de 41% da decis√£o do modelo.\n",
        "\n",
        "A√ß√£o Acion√°vel: A empresa deve criar um incentivo din√¢mico para motoristas aceitarem corridas com alto tempo_medio_viagem. Isso pode ser um b√¥nus por aceita√ß√£o ou uma garantia de que a pr√≥xima corrida ser√° pr√≥xima ao ponto de desembarque final.\n",
        "\n",
        "A√ß√£o 2: Gerenciamento Ativo da Qualidade do Cliente (Risco)\n",
        "Insight: A avaliacao_cliente (7.87%) √© mais importante do que o tempo_medio_cancelamento e o valor_reserva.\n",
        "\n",
        "A√ß√£o Acion√°vel: O modelo deve ser integrado a um sistema de prioriza√ß√£o: clientes com avalia√ß√µes abaixo de, por exemplo, 4.5 devem ter suas solicita√ß√µes de reserva enviadas com um pequeno b√¥nus adicional para o motorista, reduzindo a chance de rejei√ß√£o inicial.\n",
        "\n",
        "A√ß√£o 3: Auditoria do Tempo de Espera e Avalia√ß√£o do Motorista\n",
        "Insight: O tempo_medio_cancelamento (6.79%) e a avaliacao_motorista (6.50%) s√£o fatores humanos cruciais.\n",
        "\n",
        "A√ß√£o Acion√°vel: Implementar um alerta para a equipe de opera√ß√µes quando o tempo_medio_cancelamento ultrapassar um certo limite (por exemplo, 5 minutos), pois isso √© um sinal de alto risco de cancelamento subsequente. Paralelamente, planos de melhoria de qualidade devem ser focados em motoristas com avalia√ß√µes abaixo de 4.5.\n",
        "\n",
        "A√ß√£o 4: Simplifica√ß√£o e Transpar√™ncia de Pagamento\n",
        "Insight: O metodo_pagamento_Desconhecido (8.51%) √© o terceiro fator mais importante.\n",
        "\n",
        "A√ß√£o Acion√°vel: A alta import√¢ncia de m√©todos desconhecidos sugere que a falta de clareza sobre como a corrida ser√° paga gera incerteza para o motorista ou cliente, aumentando o risco de cancelamento. A empresa deve simplificar e garantir a m√°xima transpar√™ncia sobre o m√©todo de pagamento no momento da reserva.\n",
        "\n",
        "3.\n",
        "\n",
        "Conclus√£o Final do Projeto\n",
        "O projeto √© um exemplo de ciclo completo da Ci√™ncia de Dados:\n",
        "\n",
        "Limpeza de Dados: Tratou nulos e fez o One-Hot Encoding.\n",
        "\n",
        "Detec√ß√£o de Falhas: Corrigiu o grave Data Leakage que inflacionava a acur√°cia.\n",
        "\n",
        "Otimiza√ß√£o: Usou o SMOTE para balancear classes e o Random Forest para robustez.\n",
        "\n",
        "Entrega de Valor: O modelo final, agora limpo e interpret√°vel, prov√™ um mapa claro de onde a empresa deve concentrar seus recursos (focando em Tempo de Viagem e Qualidade do Cliente), maximizando a chance de uma corrida ser conclu√≠da."
      ],
      "metadata": {
        "id": "4-ZSvoeMSRil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclus√£o Final do Projeto: Otimiza√ß√£o de Classifica√ß√£o de Reservas\n",
        "O projeto iniciou-se com a Regress√£o Log√≠stica como baseline (acur√°cia de 81%) e revelou que as classes minorit√°rias, como No Driver Found, eram mal previstas. O principal avan√ßo foi a transi√ß√£o metodol√≥gica para um modelo de ponta, corrigindo falhas graves no processo.\n",
        "\n",
        "Primeiro, foi fundamental a corre√ß√£o de Vazamento de Dados (Data Leakage), garantindo que o modelo fizesse uma previs√£o real e n√£o uma consulta. Em seguida, a t√©cnica de SMOTE foi aplicada para balancear as classes minorit√°rias no conjunto de treino. Esta base otimizada foi utilizada para treinar um modelo Random Forest, um m√©todo de Ensemble Learning, que teve sua performance maximizada via GridSearchCV (ajuste de hiperpar√¢metros).\n",
        "\n",
        "O resultado final foi um modelo com 94% de acur√°cia, que elevou drasticamente o Recall para classes cr√≠ticas (ex: No Driver Found de 30% para 100%). A an√°lise de Feature Importance concluiu que a dura√ß√£o da viagem √© o principal fator preditor, fornecendo o insight acion√°vel definitivo para o neg√≥cio. O projeto valida a efic√°cia de modelos complexos e a import√¢ncia de t√©cnicas avan√ßadas para a gera√ß√£o de valor."
      ],
      "metadata": {
        "id": "z1v_sCKODVZu"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4aJ6bcPLybcRvmZ/f/S+N",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}